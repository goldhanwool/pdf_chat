
472>>-----------------------------------------Skip-gram model is a word representation model that aims to learn word vector representations by predicting nearby words. This paper presents several extensions of the original Skip-gram model, including sub-sampling of frequent words during training for faster training and improved accuracy, as well as a simplified variant of Noise Contrastive Estimation (NCE) for better vector representations. The limitations of word representations in representing idiomatic phrases are discussed, and the benefits of using phrase vectors instead are highlighted. The extension from word-based to phrase-based models is described, where phrases are treated as individual tokens during training. Additionally, the compositional property of the Skip-gram model is explored, showing that simple vector addition can produce meaningful results in terms of language understanding.
-----------------------------------------
스킵그램 모델은 단어 표현 모델로, 주변 단어를 예측하여 단어 벡터 표현을 학습하는 것을 목표로 한다. 이 논문은 더 빠른 훈련과 향상된 정확도를 위해 훈련 중 빈번한 단어의 하위 샘플링과 더 나은 벡터 표현을 위한 NCE(Noise Contrastative Estimation)의 단순화된 변형을 포함하여 원래 스킵그램 모델의 여러 확장을 제시한다. 관용구를 표현하는 데 있어 단어 표현의 한계를 논의하고, 대신 구문 벡터를 사용하는 것의 이점을 강조한다. 단어 기반에서 구문 기반 모델로의 확장이 설명되며, 여기서 구문은 훈련 중에 개별 토큰으로 취급된다. 또한 스킵그램 모형의 구성적 속성을 탐색하여 단순 벡터 덧셈이 언어 이해의 측면에서 유의미한 결과를 도출할 수 있음을 보여준다.
-----------------------------------------
